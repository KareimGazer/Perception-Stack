{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00562cf-70d1-436c-8480-98f5f68e688e",
   "metadata": {},
   "source": [
    "# Main Pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c0f1b-1e8c-4113-9569-e19fd028005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5d998-e751-4299-8f86-c1d4a7dc1b8f",
   "metadata": {},
   "source": [
    "Cameras needed to be calibrated first to remove distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d38afd-d747-437b-ba61-23c752412f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calibrate_camera # calibration module\n",
    "mtx, dist = calibrate_camera.calibrate(9, 6, 'camera_cal/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd09b930-5195-455e-a1c7-403605cd490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.15777818e+03, 0.00000000e+00, 6.67113857e+02],\n",
       "        [0.00000000e+00, 1.15282217e+03, 3.86124583e+02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       " array([[-0.24688507, -0.02373156, -0.00109831,  0.00035107, -0.00259866]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc74e2-9bd8-45b9-b0d0-d59456abf9ee",
   "metadata": {},
   "source": [
    "after we got the matrix and distortion coefficients we apply them to checkboards images to check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d50ed-fba0-469f-ab24-3f38b9321496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05a4c03a-f6bb-4b87-8589-700a0d3f64d6",
   "metadata": {},
   "source": [
    "we save the results in a pickle dictionary so we don't need to repeat the pipeline and gain performance improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a076e-55f0-44bc-8af0-a7c70b7e1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b245ee1-737d-4f85-b531-867981e9d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525f01a-93ba-4db7-aa02-5c821eb4cce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e5d3c-6a93-4892-9017-ef6082a75472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599946d-8033-4d0b-9f29-9ec92f130a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260a89b",
   "metadata": {},
   "source": [
    "## pipeline prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dc1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bird_view\n",
    "import lanes\n",
    "import rad\n",
    "import sobel\n",
    "\n",
    "prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty = (None, None, None, None)\n",
    "\n",
    "def pipeline(frame, mtx, dist):\n",
    "    global prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty\n",
    "    undistored_image = calibrate_camera.undistort(frame, mtx, dist)\n",
    "    # image_rgb = cv2.cvtColor(undistored_image, cv2.COLOR_BGR2RGB)\n",
    "    combined_soble = sobel.get_binary(undistored_image, ksize)\n",
    "    # return combined_soble\n",
    "\n",
    "    binary_warped, matrix, matrix_inv = bird_view.get_bird_view(combined_soble)\n",
    "    \n",
    "    out_img, left_fitx, right_fitx, ploty = (None, None, None, None)\n",
    "    try:\n",
    "        out_img, left_fitx, right_fitx, ploty = lanes.fit_polynomial(binary_warped, 10, 90, 50)\n",
    "        prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty = out_img, left_fitx, right_fitx, ploty\n",
    "    except:\n",
    "        out_img, left_fitx, right_fitx, ploty = prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty\n",
    "    \n",
    "    result = lanes.draw_path(binary_warped, left_fitx, right_fitx, ploty, matrix_inv, frame)\n",
    "    \n",
    "    # calculating curvature and center offset\n",
    "    left_curverad, right_curverad, real_offset = rad.measure_curvature_real(binary_warped, left_fitx, right_fitx, ploty)\n",
    "    curve_info = \"radius of curvature ({} Km, {} Km)\".format(str(round(left_curverad/1000, 2)), \n",
    "                                                           str(round(right_curverad/1000, 2)))\n",
    "    \n",
    "    center_info = \"offset from center  = {} m\".format(str(round(real_offset, 2)))\n",
    "    \n",
    "    detailed = cv2.putText(result, curve_info, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0 , 0), 2, cv2.LINE_AA)\n",
    "    detailed = cv2.putText(detailed, center_info, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0 , 0), 2, cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ad25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ef6fd39",
   "metadata": {},
   "source": [
    "## Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a110229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sobel\n",
    "import calibrate_camera\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "# cap = cv2.VideoCapture('challenge_video.mp4')\n",
    "# cap = cv2.VideoCapture('harder_challenge_video.mp4') \n",
    "\n",
    "ksize = 3\n",
    "\n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (1280, 720), fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    result = pipeline(frame, mtx, dist)\n",
    "    cv2.imshow('gblur', result)\n",
    "\n",
    " \n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549b01",
   "metadata": {},
   "source": [
    "## store video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "ksize = 3\n",
    "\n",
    "# cap = cv2.VideoCapture('challenge_video.mp4')\n",
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "\n",
    "video_file = 'race1.mp4'\n",
    "frame_size = (1280, 720)\n",
    "fps = 40\n",
    "out = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'MP4V'), fps, frame_size)\n",
    "\n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, frame_size, fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    result = pipeline(frame, mtx, dist)\n",
    "    cv2.imshow('image', result)\n",
    "    # result_bgr = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    out.write(result)\n",
    "\n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
