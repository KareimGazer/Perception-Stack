{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00562cf-70d1-436c-8480-98f5f68e688e",
   "metadata": {},
   "source": [
    "# Main Pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c0f1b-1e8c-4113-9569-e19fd028005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5d998-e751-4299-8f86-c1d4a7dc1b8f",
   "metadata": {},
   "source": [
    "Cameras needed to be calibrated first to remove distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d38afd-d747-437b-ba61-23c752412f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calibrate_camera # calibration module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09b930-5195-455e-a1c7-403605cd490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx, dist = calibrate_camera.calibrate(9, 6, 'camera_cal/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc74e2-9bd8-45b9-b0d0-d59456abf9ee",
   "metadata": {},
   "source": [
    "after we got the matrix and distortion coefficients we apply them to checkboards images to check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d50ed-fba0-469f-ab24-3f38b9321496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "images_names = glob.glob('camera_cal/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    calibrate_camera.undistort(image, mtx, dist, \n",
    "                               'output_images/calibrated_boards/test{}.jpg'.format(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4c03a-f6bb-4b87-8589-700a0d3f64d6",
   "metadata": {},
   "source": [
    "we save the results in a pickle dictionary so we don't need to repeat the pipeline and gain performance improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a076e-55f0-44bc-8af0-a7c70b7e1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b245ee1-737d-4f85-b531-867981e9d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names = glob.glob('test_images/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    calibrate_camera.undistort(image, mtx, dist, \n",
    "                               'output_images/calibrated_roads/road{}.jpg'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525f01a-93ba-4db7-aa02-5c821eb4cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import sobel # sobel module reads images in RGB using matplot lib\n",
    "images_names = glob.glob('output_images/calibrated_roads/*.jpg')\n",
    "ksize = 3\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = mpimg.imread(image_name)\n",
    "    combined_binary = sobel.get_binary(image, ksize)\n",
    "    plt.imsave('output_images/roads_binary/{}.jpg'.format(index), combined_binary,\n",
    "               cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e5d3c-6a93-4892-9017-ef6082a75472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b599946d-8033-4d0b-9f29-9ec92f130a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import bird_view\n",
    "import lanes\n",
    "import cv2\n",
    "\n",
    "images_names = glob.glob('output_images/roads_binary/*.jpg')\n",
    "undists = glob.glob('output_images/calibrated_roads/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = mpimg.imread(image_name)\n",
    "    binary_warped, matrix, matrix_inv = bird_view.get_bird_view(image)\n",
    "    plt.imsave('output_images/roads_view/{}.jpg'.format(index), binary_warped,\n",
    "               cmap='gray')\n",
    "    print(binary_warped.shape)\n",
    "    \n",
    "    binary_warped = cv2.cvtColor(binary_warped, cv2.COLOR_RGB2GRAY)\n",
    "    # accepts binary image\n",
    "    out_img, left_fitx, right_fitx, ploty = lanes.fit_polynomial(binary_warped)\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, matrix_inv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    undist = plt.imread(undists[index])\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    plt.imsave('output_images/roads_maped/{}.jpg'.format(index), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803371b9-0104-4dd1-9fd8-50424e9323c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
