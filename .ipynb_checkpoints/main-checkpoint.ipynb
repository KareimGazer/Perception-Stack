{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00562cf-70d1-436c-8480-98f5f68e688e",
   "metadata": {},
   "source": [
    "# Simple Perception Stack For Self-Driving Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf712b24",
   "metadata": {},
   "source": [
    "![Logo](./logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f93acb",
   "metadata": {},
   "source": [
    "**Kareim Tarek AbdelAzeem Amin         1701002**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58ec9a",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "In this first part of the project we aim to detect and draw the lane line. the frames of the video pass through a pipleline to get processed and achieve the required results. In the following sections we demonstrate those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61908d",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "to achieve that the video frame pass through the following steps of the pipeline\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72363d80",
   "metadata": {},
   "source": [
    "# prototype\n",
    "the following snippets of code demonstrate the pipleline on images. for videos please run `run.sh` in terminal or see the last two code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36389aaa",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c0f1b-1e8c-4113-9569-e19fd028005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5d998-e751-4299-8f86-c1d4a7dc1b8f",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "Cameras needed to be calibrated first to remove distortion. we import `calibrate_camera` module and compute correction matrix and distortion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d38afd-d747-437b-ba61-23c752412f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calibrate_camera # calibration module\n",
    "mtx, dist = calibrate_camera.calibrate(9, 6, 'camera_cal/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09b930-5195-455e-a1c7-403605cd490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc74e2-9bd8-45b9-b0d0-d59456abf9ee",
   "metadata": {},
   "source": [
    "after we got the matrix and distortion coefficients we apply them to checkboards images to check the results.\n",
    "results can be found at `output_images/calibrated_boards/`, and a sample is plotted inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "images_names = glob.glob('camera_cal/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    undistored_image = calibrate_camera.undistort(image, mtx, dist)\n",
    "    cv2.imwrite('output_images/calibrated_boards/test{}.jpg'.format(index), undistored_image)\n",
    "\n",
    "cal_board = plt.imread('output_images/calibrated_boards/test0.jpg')\n",
    "plt.imshow(cal_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4c03a-f6bb-4b87-8589-700a0d3f64d6",
   "metadata": {},
   "source": [
    "we save the results in a pickle dictionary so we don't need to repeat the pipeline and gain performance improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a076e-55f0-44bc-8af0-a7c70b7e1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567c52a",
   "metadata": {},
   "source": [
    "## Undistort\n",
    "Now we try to correct the road Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525f01a-93ba-4db7-aa02-5c821eb4cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "images_names = glob.glob('test_images/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    undistorted_image = calibrate_camera.undistort(image, mtx, dist)\n",
    "    cv2.imwrite('output_images/calibrated_roads/road{}.jpg'.format(index), undistorted_image)\n",
    "\n",
    "undist_road = plt.imread('output_images/calibrated_roads/road0.jpg')\n",
    "plt.imshow(undist_road)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2802fb",
   "metadata": {},
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "I used combination of the B channel In LAB color representation anded with S channel in HLS representation to detect the left yellow lane, and the L channel in the HLS color representation to detect white right lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599946d-8033-4d0b-9f29-9ec92f130a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import sobel # sobel module reads images in RGB using matplot lib\n",
    "images_names = glob.glob('output_images/calibrated_roads/*.jpg')\n",
    "ksize = 3\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    combined_binary = sobel.get_binary(image, ksize)\n",
    "    plt.imsave('output_images/roads_binary/{}.jpg'.format(index), combined_binary,\n",
    "               cmap='gray')\n",
    "thresh_road = plt.imread('output_images/roads_binary/0.jpg')\n",
    "plt.imshow(thresh_road)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5a31",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import bird_view\n",
    "import lanes\n",
    "import cv2\n",
    "import rad\n",
    "\n",
    "images_names = glob.glob('output_images/roads_binary/*.jpg')\n",
    "# undists = glob.glob('output_images/calibrated_roads/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = mpimg.imread(image_name)\n",
    "    binary_warped, matrix, matrix_inv = bird_view.get_bird_view(image)\n",
    "    plt.imsave('output_images/roads_view/{}.jpg'.format(index), binary_warped,\n",
    "               cmap='gray')\n",
    "thresh_road = plt.imread('output_images/roads_view/0.jpg')\n",
    "plt.imshow(thresh_road)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b7d0e",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import bird_view\n",
    "import lanes\n",
    "import cv2\n",
    "import rad\n",
    "\n",
    "images_names = glob.glob('output_images/roads_view/*.jpg')\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = mpimg.imread(image_name)\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    out_img, left_fitx, right_fitx, ploty = lanes.fit_polynomial(image_gray)\n",
    "    plt.imsave('output_images/roads_plt/{}.jpg'.format(index), out_img)\n",
    "plt_road = plt.imread('output_images/roads_plt/0.jpg')\n",
    "plt.imshow(plt_road)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5da41",
   "metadata": {},
   "source": [
    "## Output visual display of the lane boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import bird_view\n",
    "import lanes\n",
    "import cv2\n",
    "import rad\n",
    "\n",
    "images_names = glob.glob('output_images/roads_binary/*.jpg')\n",
    "undists = glob.glob('output_images/calibrated_roads/*.jpg')\n",
    "\n",
    "for index, image_name in enumerate(images_names):\n",
    "    image = mpimg.imread(image_name)\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    binary_warped, matrix, matrix_inv = bird_view.get_bird_view(image_gray)\n",
    "    out_img, left_fitx, right_fitx, ploty = lanes.fit_polynomial(binary_warped)\n",
    "    \n",
    "    undist = plt.imread(undists[index])\n",
    "    result = lanes.draw_path(binary_warped, left_fitx, right_fitx, ploty, matrix_inv, undist)\n",
    "    \n",
    "    plt.imsave('output_images/roads_maped/{}.jpg'.format(index), result)\n",
    "plt_road = plt.imread('output_images/roads_maped/0.jpg')\n",
    "plt.imshow(plt_road)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260a89b",
   "metadata": {},
   "source": [
    "## pipeline prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bird_view\n",
    "import lanes\n",
    "import rad\n",
    "import sobel\n",
    "\n",
    "prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty = (None, None, None, None)\n",
    "\n",
    "def pipeline(frame, mtx, dist):\n",
    "    global prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty\n",
    "    undistored_image = calibrate_camera.undistort(frame, mtx, dist)\n",
    "    # image_rgb = cv2.cvtColor(undistored_image, cv2.COLOR_BGR2RGB)\n",
    "    combined_soble = sobel.get_binary(undistored_image, ksize)\n",
    "    return combined_soble\n",
    "\n",
    "    binary_warped, matrix, matrix_inv = bird_view.get_bird_view(combined_soble)\n",
    "    \n",
    "    out_img, left_fitx, right_fitx, ploty = (None, None, None, None)\n",
    "    try:\n",
    "        out_img, left_fitx, right_fitx, ploty = lanes.fit_polynomial(binary_warped, 10, 90, 50)\n",
    "        prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty = out_img, left_fitx, right_fitx, ploty\n",
    "    except:\n",
    "        out_img, left_fitx, right_fitx, ploty = prev_out_img, prev_left_fitx, prev_right_fitx, prev_ploty\n",
    "    \n",
    "    result = lanes.draw_path(binary_warped, left_fitx, right_fitx, ploty, matrix_inv, frame)\n",
    "    \n",
    "    # calculating curvature and center offset\n",
    "    left_curverad, right_curverad, real_offset = rad.measure_curvature_real(binary_warped, left_fitx, right_fitx, ploty)\n",
    "    curve_info = \"radius of curvature ({} Km, {} Km)\".format(str(round(left_curverad/1000, 2)), \n",
    "                                                           str(round(right_curverad/1000, 2)))\n",
    "    \n",
    "    center_info = \"offset from center  = {} m\".format(str(round(real_offset, 2)))\n",
    "    \n",
    "    detailed = cv2.putText(result, curve_info, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0 , 0), 2, cv2.LINE_AA)\n",
    "    detailed = cv2.putText(detailed, center_info, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0 , 0), 2, cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6fd39",
   "metadata": {},
   "source": [
    "## Live Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a110229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sobel\n",
    "import calibrate_camera\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "# cap = cv2.VideoCapture('challenge_video.mp4')\n",
    "# cap = cv2.VideoCapture('harder_challenge_video.mp4') \n",
    "\n",
    "ksize = 3\n",
    "\n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (1280, 720), fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    result = pipeline(frame, mtx, dist)\n",
    "    cv2.imshow('gblur', result)\n",
    "\n",
    " \n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549b01",
   "metadata": {},
   "source": [
    "## store video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "ksize = 3\n",
    "\n",
    "# cap = cv2.VideoCapture('challenge_video.mp4')\n",
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "\n",
    "video_file = 'race1.mp4'\n",
    "frame_size = (1280, 720)\n",
    "fps = 40\n",
    "out = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'MP4V'), fps, frame_size)\n",
    "\n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, frame_size, fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    result = pipeline(frame, mtx, dist)\n",
    "    cv2.imshow('image', result)\n",
    "    # result_bgr = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    out.write(result)\n",
    "\n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
